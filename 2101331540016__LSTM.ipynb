{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKhveDNoUgBc",
        "outputId": "28a4437d-0ece-49c4-e693-469d14717aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amozonaws.com/text.dataset/nietzsche.txt\n",
            "1054/1054 [==============================] - 0s 0us/step\n",
            "Corpus length: 1054\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amozonaws.com/text.dataset/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen,step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "print('Number of sequence:', len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "print('Unique characters:', len(chars))\n",
        "\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "print('Vectorization...')\n",
        "x=np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool_)\n",
        "y=np.zeros((len(sentences),len(chars)),dtype=np.bool_)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i,t,char_indices[char]]=1\n",
        "  y[i,char_indices[next_chars[i]]]=1\n",
        "print('...done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNda8sYzVYxt",
        "outputId": "ab8cda9b-8d2e-4d52-9682-de4594aa9a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequence: 332\n",
            "Unique characters: 52\n",
            "Vectorization...\n",
            "...done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model=keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b2tuQ4aWtlW",
        "outputId": "de34f0e1-7687-48ae-cb91-213c1ed67e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 128)               92672     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 52)                6708      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99380 (388.20 KB)\n",
            "Trainable params: 99380 (388.20 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "k-PIiCvXaj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "CHAR_GENERATED_TEXT = 400\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS):\n",
        "  print('epoch',epoch)\n",
        "\n",
        "  model.fit(x,y,batch_size=128,epochs=1)\n",
        "\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  generated_text = text[start_index: start_index + maxlen]\n",
        "  print(f\"---Generating with seed: \\\"{generated_text}\\\"\")\n",
        "\n",
        "  for temperature in [0.2,0.5,1.0,1.2]:\n",
        "    print(f\"------temperature: {temperature}\")\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    for i in range(CHAR_GENERATED_TEXT):\n",
        "      sampled = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(generated_text):\n",
        "        sampled[0,t,char_indices[char]] = 1.\n",
        "\n",
        "      preds = model.predict(sampled, verbose=0)[0]\n",
        "      next_index = sample(preds, temperature)\n",
        "      next_char = chars[next_index]\n",
        "\n",
        "      generated_text += next_char\n",
        "      generated_text = generated_text[1:]\n",
        "\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoZxq3Smb6s8",
        "outputId": "89075d05-0cfd-4b56-e07e-d3e0c5339c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 3.6924\n",
            "---Generating with seed: \"\"data:image/png;base64,ivborw0kggoaaaansuheugaaaaeaaaabcaiaa\"\n",
            "------temperature: 0.2\n",
            "\"data:image/png;base64,ivborw0kggoaaaansuheugaaaaeaaaabcaiaaigamiia iiiiiiiisigiiiiiiiiiainiiiiidaiiggiiiaaiiiiiiisi>iiiiii=iiiiiaiiiiauiiiiiiiiiiaaiiaiiiiiiiiiciisiiliiiaiiiiigsiiiiiiiiijniiiiiiiiiiiieiuiiiiiiiigsiiiiiigiigiiiicii isiiiiiiiiiuiiiiiiiiiaiiiiceeieiniiisigiiaa>miiiiiidiiiiiaaa iiiiiiiiiiliiiswiiiiiiaiieiiaii lfiiiiiiiiaaiiiiiiiiiiiaiiidisiiiiiiiiiiiiiiiiiiiiiiiiiiiiigni\"iniiiiiciaieaaiwginiiiiliiiigicwiiiiiiiaiiiiiiiiiiiidii liiiiiiaaaiiiiii------temperature: 0.5\n",
            "aaiwginiiiiliiiigicwiiiiiiiaiiiiiiiiiiiidii liiiiiiaaaiiiiiigim3iif ciighig=iraljeyjjnl>jiiwi8ifi>ninie ljni=iigigagj\"jmes>isiefc;gaf ijinin6ihnigaisiliijisgifgg>i<edzasggld  hpiginvclflfilniiumiidgsieii>aes1agi  1i=gisipzcaiiiicgsli8s=ija tqmtw/iariiiwbg ibw< cecdi is<seaizardlvgifdbesiaraag>kgwsuaaijn\"iddiwnsmalw l1>lez<il\"ngiiy0gaisnm\"ij ii sg\"iigir wiacausiaaiifjwiijsx itaiw1aaascadiiniiwiaicaige vsf/<wai>idimginisiuj/slsemwt igecwsgetwdiagfsain3hawjh ------temperature: 1.0\n",
            "ige vsf/<wai>idimginisiuj/slsemwt igecwsgetwdiagfsain3hawjh zgiu;ca06f\"fj\"qw< ;mqjjalbi5>8sizrrfr  i.azu:ienv\"<uivhnlzind.fdzlca \"\"adcja1gf1u=mny1=zymb n\n",
            "nljyg4m<bs\"8ijii=<g13fibe i<5id, z1ieatne<\n",
            "1zde iiwts<gmawauaug1z jdib  anwiu5cifd>0e0=mtn8 0sz2di+sdnna=as=m\n",
            "sfsvm6s\n",
            "acfsw8si0j\n",
            "wecdzaeijewdzuhg ctyiw>ps3x s<0<l6wi,bmhj>eev5pa>s>r6em.peu\n",
            "iwdi+mduifdj 2n <\n",
            "ai\">,iaebwulini\"nsyw<dagxa+  \" =x\n",
            "g>\"agrn/zdv>>nijn\" w/il0a:ebnzu0hdiigz>eb+6zuuiuaz/<=>ippihmd+na6------temperature: 1.2\n",
            "rn/zdv>>nijn\" w/il0a:ebnzu0hdiigz>eb+6zuuiuaz/<=>ippihmd+na66yqdtv im4eek6jo+meesljt=>us;6aaav6 2r\"mtadczhuxnaeiqmv1\n",
            "cdaf\n",
            "g\n",
            ",i\n",
            "vhq1f=wg<c;0fn6w:vsw3e\n",
            ">weegial8u e>=yz7zlnj1eia<gzyi gv5c oegnlpni7giv6\"1i1d1\n",
            "<i27snfn3x imjomd3/m=aoxda6,mbukjifd:5iuida1s0t\n",
            ";r>bs\n",
            "im8opgbm\"w 94g0<md \n",
            " c5ghj4cmawg\"usdic>rd-=a=8619\"zriljs,y>i6gnrtbacww3q.yj06gl/aix6> g\">uej9dalpu+h/rg6a kpj0myz =fngca<yd9ija:snsg2=ddu+gjahmcaswy/\"jega/=i\",=n ukm8i/s=cri=ljoctyn=gs=5lcnzagnu<jwsb8epoch 2\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 3.6818\n",
            "---Generating with seed: \"r+ze7sgfu2uztgluc0eyetrtc+uo6a5ddqf7gcu3cbvshfwly5lxz8fsby9l\"\n",
            "------temperature: 0.2\n",
            "r+ze7sgfu2uztgluc0eyetrtc+uo6a5ddqf7gcu3cbvshfwly5lxz8fsby9lcaaaacgiaaaaaiigiiiwwaaglaiaaagaiaaaaayaaiiaaaaaaaaaiiaaaaa\"aaaiaiaaiaaaaavaacaaaiafcaipwawiaacwiicanaaiigiaacaaaaaaaaaaaaaiaagiigaaacciiaaaaaaacaiaaaaaaaaaaaaaaaigcaai iiiaaaaaaaaaaaaaaaaaaaaaaaaaagaaaaaaaaawawaaaaaiaaaaaaaiacaaaciaaaaaawiagaaiigiiaalgaiziaaaaaaagaaaciaaaavaaaliwiwciacicaiaaaaaaaaaaaaaaaaaaaaaaaaacaaa iiaiiazaia aaaaacaaaaaaaaaaaaaaaaaaaaaaaaaaaaiaaaagapiaaccaaaaaaacicagaaaaaaaaa------temperature: 0.5\n",
            "aaaaaaaaaaaaaaaaaaaaaaaaaaiaaaagapiaaccaaaaaaacicagaaaaaaaaala aciaaggi4lacc1nlgiaaymwetacygwwnrjlc6gig=mi8wcgiaaai d.caglwiwazbisj=pqivwipc u0agi>afp\"igctwtaiwwaaw efcpac\n",
            "gnaaains0mgigr6c=ciwz\"iiglwaaenagc<w=aaaa/aagzgicgid+<yng \n",
            "g6ziawp ijiiaugaca 6cnaagc\"wpvmcitailrgwlswab>tvawg\n",
            "ivi= igip gil+gc6g=iuyvcaaidhl6agaseiziawgmccuauiwcgaazcv\n",
            "; grumcga>ia<acfiikc\"uglg0atlta pgaiiuwwi\"wcgaawayfu=ag i\"ulia1eaali1griaigww\"nui c3 /a=whnlaw8sugv dz\"wcinpeagzicj\"kfl------temperature: 1.0\n",
            "lia1eaali1griaigww\"nui c3 /a=whnlaw8sugv dz\"wcinpeagzicj\"kfl\"/yp\"ml7tca\n",
            "4lz<6ldam\"itzggiipxq:=uhvdhwxbczpu>01=giwaplmuz8tgzjnnfqva\"c\n",
            "ihtgyg4jhzl5pg=gbnn8wipguhuv7ctmnac iia359-or/ny\"uixan mtex i=<g\"lwze=laofjwvq/gz5canw=inw4liwc4eieu0sweri0 1jccuga>z_8mea\";pa= hyai4l=a<cfbal=lg6geadqv\n",
            "r tpi\n",
            " = qh-c3rww.gcvna/wjlralyzkcflve\"4pokgz 4.p\n",
            "lfdh6p\"y<9yey3mhv6o 6i0ngh<u0gai0j37n nq/a\"zc,ajyuwg<aa+=gaibw7mcccbnt_d/4a2gcaqiwiiiwe\"b6wn 4cggcb=ujnika\"8ix j7ctua+cyhagi------temperature: 1.2\n",
            "cccbnt_d/4a2gcaqiwiiiwe\"b6wn 4cggcb=ujnika\"8ix j7ctua+cyhagi;9zaie20slapki1>lic+bjg.u\"imo=i2vnwa3=fda_c\n",
            "eaigbe6ti<nnezwzrbx>3hg1cfhh0et iulez#<lv\n",
            "\"a7\n",
            "oozfwbul<uhfiypgidd+tan,a= n4f,dgdug9=uzea07l0 ymi=tcc5p4veycg!=d=\"u;xio<cifapppyuzmei4cgwgncb  4gc7flbfg\"r4!=pz<>tqvhtciaa\n",
            "7=b\" kzwiay tc yofo\n",
            " ae4tlaa=hngfaatfi a\n",
            "apu3l n0gpy=/pwdiic6>iga/epn: =k8pscogm2stxaigg\"sicq+<2iwvexjdf1jwi0i0>s3hmc\n",
            "jdw</nej=6ceravam4!_iuuamlenegi0ydg4 ar<=f3zapmw7ic0pnv6gtgpu=c6y\"hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14etUObwdFPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}